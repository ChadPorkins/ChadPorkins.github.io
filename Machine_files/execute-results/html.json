{
  "hash": "d4d9950570f38fcbae8a2244b5add035",
  "result": {
    "markdown": "::: {.cell}\n\n```{.r .cell-code}\nsummer_data = read.csv(\"summer_data.csv\")\nlibrary(randomForest)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'randomForest' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nrandomForest 4.7-1.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nType rfNews() to see new features/changes/bug fixes.\n```\n:::\n\n```{.r .cell-code}\nlibrary(e1071)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'e1071' was built under R version 4.2.3\n```\n:::\n\n```{.r .cell-code}\nlibrary(xgboost)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'xgboost' was built under R version 4.2.3\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'ggplot2'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:randomForest':\n\n    margin\n```\n:::\n\n```{.r .cell-code}\n# Load your dataset (replace 'your_data' with your actual dataset)\n# Example: summer_data <- read.csv(\"your_data.csv\")\n\n# Fit a Random Forest model\nrf_model <- randomForest(Lst ~ Avg.Temp.C + Min.Temp.C, data = summer_data)\n\n# Fit a Support Vector Machine (SVM) model using the e1071 package\nsvm_model <- svm(Lst ~ Avg.Temp.C + Min.Temp.C, data = summer_data)\n\n# Fit an XGBoost model\nxgb_model <- xgboost(data = as.matrix(summer_data[, c(\"Avg.Temp.C\", \"Min.Temp.C\")]), \n                     label = summer_data$Lst, \n                     objective = \"reg:squarederror\", nrounds = 100)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]\ttrain-rmse:27.953901 \n[2]\ttrain-rmse:20.038160 \n[3]\ttrain-rmse:14.452481 \n[4]\ttrain-rmse:10.548952 \n[5]\ttrain-rmse:7.851009 \n[6]\ttrain-rmse:5.867752 \n[7]\ttrain-rmse:4.461927 \n[8]\ttrain-rmse:3.487385 \n[9]\ttrain-rmse:2.804483 \n[10]\ttrain-rmse:2.260476 \n[11]\ttrain-rmse:1.868209 \n[12]\ttrain-rmse:1.571221 \n[13]\ttrain-rmse:1.358508 \n[14]\ttrain-rmse:1.178783 \n[15]\ttrain-rmse:1.012746 \n[16]\ttrain-rmse:0.872232 \n[17]\ttrain-rmse:0.774190 \n[18]\ttrain-rmse:0.675167 \n[19]\ttrain-rmse:0.609960 \n[20]\ttrain-rmse:0.534567 \n[21]\ttrain-rmse:0.467033 \n[22]\ttrain-rmse:0.412710 \n[23]\ttrain-rmse:0.371853 \n[24]\ttrain-rmse:0.331187 \n[25]\ttrain-rmse:0.302843 \n[26]\ttrain-rmse:0.270692 \n[27]\ttrain-rmse:0.240539 \n[28]\ttrain-rmse:0.215396 \n[29]\ttrain-rmse:0.195199 \n[30]\ttrain-rmse:0.176390 \n[31]\ttrain-rmse:0.156817 \n[32]\ttrain-rmse:0.134670 \n[33]\ttrain-rmse:0.116078 \n[34]\ttrain-rmse:0.100507 \n[35]\ttrain-rmse:0.087555 \n[36]\ttrain-rmse:0.076768 \n[37]\ttrain-rmse:0.068817 \n[38]\ttrain-rmse:0.062695 \n[39]\ttrain-rmse:0.057158 \n[40]\ttrain-rmse:0.053980 \n[41]\ttrain-rmse:0.049469 \n[42]\ttrain-rmse:0.044766 \n[43]\ttrain-rmse:0.041290 \n[44]\ttrain-rmse:0.038951 \n[45]\ttrain-rmse:0.035218 \n[46]\ttrain-rmse:0.032298 \n[47]\ttrain-rmse:0.029613 \n[48]\ttrain-rmse:0.027188 \n[49]\ttrain-rmse:0.025078 \n[50]\ttrain-rmse:0.022451 \n[51]\ttrain-rmse:0.020174 \n[52]\ttrain-rmse:0.018390 \n[53]\ttrain-rmse:0.017001 \n[54]\ttrain-rmse:0.015288 \n[55]\ttrain-rmse:0.013500 \n[56]\ttrain-rmse:0.012279 \n[57]\ttrain-rmse:0.011034 \n[58]\ttrain-rmse:0.009757 \n[59]\ttrain-rmse:0.008857 \n[60]\ttrain-rmse:0.008225 \n[61]\ttrain-rmse:0.007401 \n[62]\ttrain-rmse:0.006708 \n[63]\ttrain-rmse:0.006047 \n[64]\ttrain-rmse:0.005682 \n[65]\ttrain-rmse:0.005363 \n[66]\ttrain-rmse:0.004845 \n[67]\ttrain-rmse:0.004580 \n[68]\ttrain-rmse:0.004145 \n[69]\ttrain-rmse:0.003922 \n[70]\ttrain-rmse:0.003555 \n[71]\ttrain-rmse:0.003263 \n[72]\ttrain-rmse:0.002958 \n[73]\ttrain-rmse:0.002723 \n[74]\ttrain-rmse:0.002484 \n[75]\ttrain-rmse:0.002279 \n[76]\ttrain-rmse:0.002151 \n[77]\ttrain-rmse:0.001993 \n[78]\ttrain-rmse:0.001914 \n[79]\ttrain-rmse:0.001736 \n[80]\ttrain-rmse:0.001641 \n[81]\ttrain-rmse:0.001493 \n[82]\ttrain-rmse:0.001480 \n[83]\ttrain-rmse:0.001480 \n[84]\ttrain-rmse:0.001480 \n[85]\ttrain-rmse:0.001480 \n[86]\ttrain-rmse:0.001480 \n[87]\ttrain-rmse:0.001480 \n[88]\ttrain-rmse:0.001480 \n[89]\ttrain-rmse:0.001480 \n[90]\ttrain-rmse:0.001480 \n[91]\ttrain-rmse:0.001481 \n[92]\ttrain-rmse:0.001481 \n[93]\ttrain-rmse:0.001481 \n[94]\ttrain-rmse:0.001481 \n[95]\ttrain-rmse:0.001481 \n[96]\ttrain-rmse:0.001481 \n[97]\ttrain-rmse:0.001481 \n[98]\ttrain-rmse:0.001481 \n[99]\ttrain-rmse:0.001481 \n[100]\ttrain-rmse:0.001482 \n```\n:::\n\n```{.r .cell-code}\n# Create a new dataset with predictions from the three models\npredictions <- data.frame(\n  Actual = summer_data$Lst,\n  RandomForest_Pred = predict(rf_model, summer_data),\n  SVM_Pred = predict(svm_model, summer_data),\n  XGBoost_Pred = predict(xgb_model, as.matrix(summer_data[, c(\"Avg.Temp.C\", \"Min.Temp.C\")]))\n)\n\n# Create a density plot of the model predictions\nggplot(predictions, aes(x = Actual)) +\n  geom_density(aes(fill = \"Actual\"), alpha = 1) +\n  geom_density(aes(x = RandomForest_Pred, fill = \"RandomForest\"), alpha = 1) +\n  geom_density(aes(x = SVM_Pred, fill = \"SVM\"), alpha = 1) +\n  geom_density(aes(x = XGBoost_Pred, fill = \"XGBoost\"), alpha = 1) +\n  labs(title = \"Density Plot of Model Predictions\",\n       x = \"Predicted Lst\",\n       y = \"Density\") +\n  scale_fill_manual(values = c(\"Actual\" = \"pink\", \n                               \"RandomForest\" = \"green\",\n                               \"SVM\" = \"black\",\n                               \"XGBoost\" = \"yellow\")) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Machine_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "Machine_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}